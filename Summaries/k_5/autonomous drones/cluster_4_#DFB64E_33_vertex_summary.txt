To perform complex tasks, drones must have the ability to move autonomously. Ensuring collision avoidance is very important for the safe movement of autonomous drones indoors.In the recent decade, the rapid development of drone technologies has made many spatial problems easier to solve, including the problem of 3D reconstruction of large objects.A review of existing solutions has shown that most of the works lack the autonomy of drones because of nonscalable mapping techniques.This paper presents a method for centralized multi-drone 3D reconstruction, which allows performing a data capturing process autonomously and requires drones equipped only with an RGB camera.The essence of the method is a multiagent approachâ€”the control center performs the workload distribution evenly and independently for all drones, allowing simultaneous flights without a high risk of collision.The center continuously receives RGB data from drones and performs each drone localization (using visual odometry estimations) and rough online mapping of the environment (using image descriptors for estimating the distance to the building).The method relies on a set of several user-defined parameters, which allows the tuning of the method for different task-specific requirements such as the number of drones, 3D model detalization, data capturing time, and energy consumption.By numerical experiments, it is shown that method parameters can be estimated by performing a set of computations requiring characteristics of drones and the building that are simple to obtain.Intelligent identification of abnormal behaviors in crowd scenes enables far more efficient development of smart cities.In the recent past, development of unmanned aerial vehicles (UAVs) has entered in the arena of flapping-wing drones, mainly due to their ability of flying at lower speed in a silent manner.